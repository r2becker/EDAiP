{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "# Chapter 1 - Getting to know a Dataset\n",
    "# Functions for initial exploration\n",
    "\n",
    "# Functions for initial exploration\n",
    "# Print the first five rows of unemployment\n",
    "print(unemployment.head())\n",
    "\n",
    "# Functions for initial exploration\n",
    "# Print a summary of non-missing values and data types in the unemployment DataFrame\n",
    "print(unemployment.info())\n",
    "\n",
    "# Functions for initial exploration\n",
    "# Print summary statistics for numerical columns in unemployment\n",
    "print(unemployment.describe())\n",
    "\n",
    "# Counting categorical values\n",
    "# Count the values associated with each continent in unemployment\n",
    "print(unemployment.value_counts('continent'))\n",
    "\n",
    "#Global unemployment in 2021\n",
    "# Import the required visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of 2021 unemployment; show a full percent in each bin\n",
    "sns.histplot(data=unemployment, x='2021', binwidth=1)\n",
    "plt.show()\n",
    "\n",
    "# Data Validation\n",
    "# Detecting data types\n",
    "\n",
    "# Update the data type of the 2019 column to a float\n",
    "unemployment[\"2019\"] = unemployment['2019'].astype(float)\n",
    "\n",
    "# Print the dtypes to check your work\n",
    "print(unemployment.dtypes)\n",
    "\n",
    "# Validating continents\n",
    "\n",
    "# Define a Series describing whether each continent is outside of Oceania\n",
    "not_oceania = ~unemployment['continent'].isin(['Oceania'])\n",
    "\n",
    "# Define a Series describing whether each continent is outside of Oceania\n",
    "not_oceania = ~unemployment[\"continent\"].isin([\"Oceania\"])\n",
    "\n",
    "# Print unemployment without records related to countries in Oceania\n",
    "print(unemployment[not_oceania])\n",
    "\n",
    "# Validating range\n",
    "\n",
    "# Print the minimum and maximum unemployment rates during 2021\n",
    "print(unemployment['2021'].min(), unemployment['2021'].max())\n",
    "\n",
    "# Create a boxplot of 2021 unemployment rates, broken down by continent\n",
    "sns.boxplot(data=unemployment, x='2021', y='continent')\n",
    "plt.show()\n",
    "\n",
    "# Summaries with .groupby() and .agg()\n",
    "\n",
    "# Print yearly mean and standard deviation grouped by continent\n",
    "print(unemployment.groupby('continent').agg(['mean', 'std']))\n",
    "\n",
    "# Named aggregations\n",
    "\n",
    "continent_summary = unemployment.groupby(\"continent\").agg(\n",
    "    # Create the mean_rate_2021 column\n",
    "    mean_rate_2021=('2021', 'mean'),\n",
    "    # Create the std_rate_2021 column\n",
    "    std_rate_2021=('2021', 'std')\n",
    ")\n",
    "print(continent_summary)\n",
    "\n",
    "# Visualizing categorical summaries\n",
    "\n",
    "# Create a bar plot of continents and their average unemployment\n",
    "sns.barplot(data=unemployment, x='continent', y='2021')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98191cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "# Chapter 2 - Data Cleaning and Imputation\n",
    "\n",
    "# Dealing with missing data\n",
    "# Count the number of missing values in each column\n",
    "print(planes.isna().sum())\n",
    "\n",
    "# Dealing with missing data\n",
    "# Count the number of missing values in each column\n",
    "print(planes.isna().sum())\n",
    "\n",
    "# Find the five percent threshold\n",
    "threshold = len(planes) * .05\n",
    "print(threshold)\n",
    "\n",
    "# Dealing with missing data\n",
    "# Count the number of missing values in each column\n",
    "print(planes.isna().sum())\n",
    "\n",
    "# Find the five percent threshold\n",
    "threshold = len(planes) * 0.05\n",
    "\n",
    "# Create a filter\n",
    "cols_to_drop = planes.columns[planes.isna().sum() <= threshold]\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Drop missing values for columns below the threshold\n",
    "planes.dropna(subset=cols_to_drop, inplace=True)\n",
    "\n",
    "print(planes.isna().sum())\n",
    "\n",
    "# Strategies for remaining missing data\n",
    "# Check the values of the Additional_Info column\n",
    "print(planes['Additional_Info'].value_counts())\n",
    "\n",
    "# Check the values of the Additional_Info column\n",
    "print(planes[\"Additional_Info\"].value_counts())\n",
    "\n",
    "# Create a box plot of Price by Airline\n",
    "sns.boxplot(data=planes, x='Airline', y='Price')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Imputing missing plane prices\n",
    "# Calculate median plane ticket prices by Airline\n",
    "airline_prices = planes.groupby(\"Airline\")[\"Price\"].median()\n",
    "\n",
    "print(airline_prices)\n",
    "\n",
    "# Convert to a dictionary\n",
    "prices_dict = airline_prices.to_dict()\n",
    "\n",
    "# Calculate median plane ticket prices by Airline\n",
    "airline_prices = planes.groupby(\"Airline\")[\"Price\"].median()\n",
    "\n",
    "print(airline_prices)\n",
    "\n",
    "# Convert to a dictionary\n",
    "prices_dict = airline_prices.to_dict()\n",
    "\n",
    "# Map the dictionary to missing values of Price by Airline\n",
    "planes[\"Price\"] = planes[\"Price\"].fillna(planes['Airline'].map(prices_dict))\n",
    "\n",
    "# Check for missing values\n",
    "print(planes.isna().sum())\n",
    "\n",
    "# Finding the number of unique values\n",
    "# Filter the DataFrame for object columns\n",
    "non_numeric = planes.select_dtypes(\"object\")\n",
    "\n",
    "# Loop through columns\n",
    "for col in non_numeric.columns:\n",
    "  \n",
    "  # Print the number of unique values\n",
    "  print(f\"Number of unique values in {col} column: \", non_numeric[col].nunique())\n",
    "\n",
    "# Flight duration categories\n",
    "# Create a list of categories\n",
    "flight_categories = ['Short-haul', 'Medium', 'Long-haul']\n",
    "\n",
    "# Adding duration categories\n",
    "# Create conditions for values in flight_categories to be created\n",
    "conditions = [\n",
    "    (planes[\"Duration\"].str.contains(short_flights)),\n",
    "    (planes[\"Duration\"].str.contains(medium_flights)),\n",
    "    (planes[\"Duration\"].str.contains(long_flights))\n",
    "]\n",
    "\n",
    "# Apply the conditions list to the flight_categories\n",
    "planes[\"Duration_Category\"] = np.select(conditions, \n",
    "                                        flight_categories,\n",
    "                                        default=\"Extreme duration\")\n",
    "\n",
    "# Plot the counts of each category\n",
    "sns.countplot(data=planes, x=\"Duration_Category\")\n",
    "plt.show()\n",
    "\n",
    "# Flight duration\n",
    "# Preview the column\n",
    "print(planes['Duration'].head())\n",
    "\n",
    "# Preview the column\n",
    "print(planes[\"Duration\"].head())\n",
    "\n",
    "# Remove the string character\n",
    "planes[\"Duration\"] = planes['Duration'].str.replace('h', '')\n",
    "print(planes['Duration'].head())\n",
    "\n",
    "# Preview the column\n",
    "print(planes[\"Duration\"].head())\n",
    "\n",
    "# Remove the string character\n",
    "planes[\"Duration\"] = planes[\"Duration\"].str.replace(\"h\", \"\")\n",
    "\n",
    "# Convert to float data type\n",
    "planes[\"Duration\"] = planes['Duration'].astype(float)\n",
    "print(planes['Duration'].head())\n",
    "\n",
    "# Preview the column\n",
    "print(planes[\"Duration\"].head())\n",
    "\n",
    "# Remove the string character\n",
    "planes[\"Duration\"] = planes[\"Duration\"].astype(str).str.replace(\"h\", \"\")\n",
    "\n",
    "# Convert to float data type\n",
    "planes[\"Duration\"] = planes[\"Duration\"].astype(float)\n",
    "\n",
    "# Plot a histogram\n",
    "sns.histplot(data=planes['Duration'])\n",
    "plt.show()\n",
    "\n",
    "# Adding descriptive statistics\n",
    "# Price standard deviation by Airline\n",
    "planes[\"airline_price_st_dev\"] = planes.groupby(\"Airline\")[\"Price\"].transform(lambda x: x.std())\n",
    "\n",
    "print(planes[[\"Airline\", \"airline_price_st_dev\"]].value_counts())\n",
    "\n",
    "# Median Duration by Airline\n",
    "# Median Duration by Airline\n",
    "planes[\"airline_median_duration\"] = planes.groupby(\"Airline\")[\"Duration\"].transform(lambda x: x.median())\n",
    "\n",
    "print(planes[[\"Airline\",\"airline_median_duration\"]].value_counts())\n",
    "\n",
    "# Mean Price by Destination\n",
    "planes[\"price_destination_mean\"] = planes.groupby(\"Destination\")[\"Price\"].transform(lambda x: x.mean())\n",
    "\n",
    "print(planes[[\"Destination\",\"price_destination_mean\"]].value_counts())\n",
    "\n",
    "# Identifying outliers\n",
    "# Plot a histogram of flight prices\n",
    "sns.histplot(data=planes, x='Price')\n",
    "plt.show()\n",
    "\n",
    "# Removing outliers\n",
    "# Find the 75th and 25th percentiles\n",
    "price_seventy_fifth = planes[\"Price\"].quantile([.75])\n",
    "price_twenty_fifth = planes[\"Price\"].quantile([.25])\n",
    "\n",
    "# Find the 75th and 25th percentiles\n",
    "price_seventy_fifth = planes[\"Price\"].quantile(0.75)\n",
    "price_twenty_fifth = planes[\"Price\"].quantile(0.25)\n",
    "\n",
    "# Calculate iqr\n",
    "prices_iqr = price_seventy_fifth - price_twenty_fifth\n",
    "\n",
    "# Calculate the thresholds\n",
    "upper = price_seventy_fifth + (prices_iqr * 1.5)\n",
    "lower = price_twenty_fifth - (prices_iqr * 1.5)\n",
    "\n",
    "# Find the 75th and 25th percentiles\n",
    "price_seventy_fifth = planes[\"Price\"].quantile(0.75)\n",
    "price_twenty_fifth = planes[\"Price\"].quantile(0.25)\n",
    "\n",
    "# Calculate iqr\n",
    "prices_iqr = price_seventy_fifth - price_twenty_fifth\n",
    "\n",
    "# Calculate the thresholds\n",
    "upper = price_seventy_fifth + (1.5 * prices_iqr)\n",
    "lower = price_twenty_fifth - (1.5 * prices_iqr)\n",
    "\n",
    "# Subset the data\n",
    "planes = planes[(planes[\"Price\"] > lower) & (planes[\"Price\"] < upper)]\n",
    "\n",
    "print(planes[\"Price\"].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "# Chapter 3 - Relationship in Data\n",
    "# Importing DateTime data\n",
    "\n",
    "# Import divorce.csv, parsing the appropriate columns as dates in the import\n",
    "divorce = pd.read_csv('divorce.csv', parse_dates=['divorce_date', 'dob_man', 'dob_woman', 'marriage_date'])\n",
    "print(divorce.dtypes)\n",
    "\n",
    "# Convert the marriage_date column to DateTime values\n",
    "divorce[\"marriage_date\"] = pd.to_datetime(divorce['marriage_date'])\n",
    "\n",
    "# Visualizing variable relationships\n",
    "# Create the scatterplot\n",
    "sns.scatterplot(data=divorce, x='marriage_duration', y='num_kids')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing multiple variable relationships\n",
    "# Create a pairplot for income_woman and marriage_duration\n",
    "sns.pairplot(data=divorce, vars=['income_woman' , 'marriage_duration'])\n",
    "plt.show()\n",
    "\n",
    "# Categorical data in scatter plots\n",
    "# Create the scatter plot\n",
    "sns.scatterplot(data=divorce, x='woman_age_marriage', y='income_woman', hue='education_woman')\n",
    "plt.show()\n",
    "\n",
    "# Exploring with KDE plots\n",
    "# Create the KDE plot\n",
    "sns.kdeplot(data=divorce,x='marriage_duration', hue='num_kids')\n",
    "plt.show()\n",
    "\n",
    "# Update the KDE plot so that marriage duration can't be smoothed too far\n",
    "sns.kdeplot(data=divorce, x=\"marriage_duration\", hue=\"num_kids\", cut=0)\n",
    "plt.show()\n",
    "\n",
    "# Update the KDE plot to show a cumulative distribution function\n",
    "sns.kdeplot(data=divorce, x=\"marriage_duration\", hue=\"num_kids\", cut=0, cumulative=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "# Chapter 4 - Turning Exploratory Analysis into Action\n",
    "# Considerations for categorical data\n",
    "# Checking for class imbalance\n",
    "# Print the relative frequency of Job_Category\n",
    "print(salaries['Job_Category'].value_counts(normalize=True))\n",
    "\n",
    "# Cross-tabulation\n",
    "# Cross-tabulate Company_Size and Experience\n",
    "print(pd.crosstab(salaries[\"Company_Size\"], salaries[\"Experience\"]))\n",
    "\n",
    "# Cross-tabulate Job_Category and Company_Size\n",
    "print(pd.crosstab(salaries[\"Job_Category\"], salaries[\"Company_Size\"]))\n",
    "\n",
    "# Cross-tabulate Job_Category and Company_Size\n",
    "print(pd.crosstab(salaries[\"Job_Category\"], salaries[\"Company_Size\"],\n",
    "            values=salaries[\"Salary_USD\"], aggfunc=\"mean\"))\n",
    "\n",
    "# Extracting features for correlation\n",
    "# Get the month of the response\n",
    "salaries[\"month\"] = salaries[\"date_of_response\"].dt.month\n",
    "\n",
    "# Extract the weekday of the response\n",
    "salaries[\"weekday\"] = salaries[\"date_of_response\"].dt.weekday\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(salaries.corr(), annot=True)\n",
    "plt.show()\n",
    "\n",
    "# Calculating salary percentiles\n",
    "# Find the 25th percentile\n",
    "twenty_fifth = salaries[\"Salary_USD\"].quantile(.25)\n",
    "\n",
    "# Save the median\n",
    "salaries_median = salaries[\"Salary_USD\"].median()\n",
    "\n",
    "# Gather the 75th percentile\n",
    "seventy_fifth = salaries[\"Salary_USD\"].quantile(.75)\n",
    "print(twenty_fifth, salaries_median, seventy_fifth)\n",
    "\n",
    "# Categorizing salaries\n",
    "# Create salary labels\n",
    "salary_labels = [\"entry\", \"mid\", \"senior\", \"exec\"]\n",
    "\n",
    "# Create the salary ranges list\n",
    "salary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries[\"Salary_USD\"].max()]\n",
    "\n",
    "# Create salary labels\n",
    "salary_labels = [\"entry\", \"mid\", \"senior\", \"exec\"]\n",
    "\n",
    "# Create the salary ranges list\n",
    "salary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries[\"Salary_USD\"].max()]\n",
    "\n",
    "# Create salary_level\n",
    "salaries[\"salary_level\"] = pd.cut(salaries[\"Salary_USD\"], labels=salary_labels, bins=salary_ranges)\n",
    "\n",
    "# Create salary labels\n",
    "salary_labels = [\"entry\", \"mid\", \"senior\", \"exec\"]\n",
    "\n",
    "# Create the salary ranges list\n",
    "salary_ranges = [0, twenty_fifth, salaries_median, seventy_fifth, salaries[\"Salary_USD\"].max()]\n",
    "\n",
    "# Create salary_level\n",
    "salaries[\"salary_level\"] = pd.cut(salaries[\"Salary_USD\"],\n",
    "                                  bins=salary_ranges,\n",
    "                                  labels=salary_labels)\n",
    "\n",
    "# Plot the count of salary levels at companies of different sizes\n",
    "sns.countplot(data=salaries, x=\"Company_Size\", hue=\"salary_level\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
